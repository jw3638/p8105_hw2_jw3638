---
title: "p8105_hw2_jw3638"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(lubridate)
```

##Problem 1
Clean pols-month.csv data: Break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.
```{r}
pols =
  read_csv("data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) |>
  mutate(
    month = month.name[month],
    year = as.integer(year),
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    )
  ) |>
  select(-prez_dem, -prez_gop, -day)

#For nice display of data in knit doc:
knitr::kable(head(pols, 5))
```

Clean snp.csv data. Arrange according to year and month.
```{r}
snp = 
  read_csv("data/fivethirtyeight_datasets/snp.csv") |>
  mutate(date = mdy(date)) |>
  separate(date, into = c("year", "month", "day"), sep = "-", convert = TRUE) |>
  mutate(
    month = month.name[month],
    year = as.integer(year)
  ) |>
  select(year, month, close)

knitr::kable(head(snp, 5))
```

Clean unemployment.csv data. Tidy it up so that it can be merged with pols-month and csv: switch from “wide” to “long” format and label formatting is consistent
```{r}
unemployment = 
  read_csv("data/fivethirtyeight_datasets/unemployment.csv") |>
  pivot_longer(
    cols = Jan:Dec,
    names_to = "month",
    values_to = "unemployment_percentage"
  ) |>
  mutate(
    month = month.name[match(month, month.abb)],
    year = as.integer(Year)
  ) |>
  select(year, month, unemployment_percentage)

knitr::kable(head(unemployment, 5))
```

Merging: Join the pols-month into snp, and merge unemployment into (pols-month in snp)
```{r}
merge1 <- 
  left_join(pols, snp, by = join_by(year, month))
merge2 <- 
  left_join(merge1, unemployment, by = join_by(year, month)) |>
  select(year, month, president, close, unemployment_percentage, everything())

knitr::kable(head(merge2, 5))
```
Dataset 1: pols-month shows data from 1947 per month for gov_gop (the number of republican governors on the associated date), rep_gop (" representatives), gov_dem ("democratic governors), sen_dem ("democratic senators), rep_dem ("democratic representatives), and president (both republican and democratic presidents). 
Dataset 2: snp shows data from 2015 of the the closing values of the S&P stock index on the associated date per month. 
Dataset 3: unemployment shows data from 1948 for unemployment_percentage per month.
Resulting dataset (merged): shows data from 1947 with columns close, unemployment_percentage, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem per month.

##Problem 2

```{r}
#Upload and Read Mr. Trash Wheel excel file, omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel.
mr_trashwheels <- 
  read_excel("data/202509+TrashWheel_Collection_Data.xlsx", 
             sheet = "Mr. Trash Wheel",
             range = "A2:N710") |>
  janitor::clean_names() |>
  #Omit rows that do not include dumpster-specific data 
  filter(!is.na(dumpster)) |> 
  mutate(
    sports_balls = as.integer(round(sports_balls))  
  ) |>
  mutate(identity = "mr", 
    year = as.numeric(year)
  )
knitr::kable(head(mr_trashwheels, 5))
```

```{r}
#Upload and Read Professor Trash Wheel excel file, omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel.
professor_trashwheels <- 
  read_excel("data/202509+TrashWheel_Collection_Data.xlsx", 
             sheet = "Professor Trash Wheel",
             range = "A2:M123") |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(identity = "professor", 
    year = as.numeric(year)
  )
knitr::kable(head(professor_trashwheels, 5))
```

```{r}
#Upload and Read Gwynns excel file, omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel.
gwynn_trashwheels <- 
    read_excel("data/202509+TrashWheel_Collection_Data.xlsx", 
             sheet = "Gwynns Falls Trash Wheel",
             range = "A2:L352") |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(
    identity = "gwynn", 
    year = as.numeric(year)
  )
knitr::kable(head(gwynn_trashwheels, 5))
```

```{r}
#Combine professor 1. Trash Wheel and Gwynnda datasets and 2. combine with the Mr. Trash Wheel dataset to produce a single dataset.
trashwheels <- bind_rows(mr_trashwheels, professor_trashwheels, gwynn_trashwheels)

#what was the total weight of trash collected by Professor Trash Wheel?
totalweightprof <- professor_trashwheels |>
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))

#What was the total number of cigarette butts collected by Gwynnda in June of 2022?
tot_gwynn_cigbutts <- gwynn_trashwheels |>
  filter(year == 2022, month == "June") |>
  summarise(tot_gwynn_cigbutts = sum(cigarette_butts, na.rm = TRUE))

knitr::kable(head(trashwheels, 10))

totalweightprof
tot_gwynn_cigbutts
```
The three datasets, Mr, Professor, and Gwynn before combining looked really similar after I cleaned them. They all have columns dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers, homes_powered, identity (which is mr, professor, or gwynn). There were a few columns that were inconsistent: Mr had sports_balls. The total weight of trash collected by Professor Trash Wheel is 256 and the total number of cigarette butts collected by Gwynnda in June of 2022 is 18120.

##Problem 3

```{r}
#Create a single, well-organized dataset
zipcodes_df <- 
  read_csv("data/zillow_data/Zip Codes.csv") |>
  janitor::clean_names() |>
#to get consistency in formatting
  mutate(file_date = as.Date(file_date, format = "%m/%d/%y"))
knitr::kable(head(zipcodes_df, 5))

```

```{r}
zori_df <- 
  read_csv("data/zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |>
  janitor::clean_names() |>
  rename(zip_code = region_name, county = county_name) |>
  pivot_longer(
    cols = starts_with("x20"),
    names_to = "date",
    values_to = "rent_price"
  ) |>
  mutate(
    county = str_remove(county, " County$"),
    date = str_remove(date, "^x"), 
    date = ymd(date) 
  )

knitr::kable(head(zori_df, 5))  
```

```{r}
#merge to create a single, final dataset
zillowdata_df <- left_join(zori_df, zipcodes_df, by= c("zip_code"), relationship =
  "many-to-many")

zillowdata_df <- zillowdata_df |>
  select(date, zip_code, neighborhood, county.x, city, state, rent_price) |>
  rename(county = county.x)

knitr::kable(head(zillowdata_df, 10))
```

```{r}
#Summary
observations <- nrow(zillowdata_df)
distinct_zips = n_distinct(zillowdata_df$zip_code)
distinct_neighborhoods = n_distinct(zillowdata_df$neighborhood)
observations
distinct_zips
distinct_neighborhoods

zips_missing_zori <- zipcodes_df |>
  anti_join(zori_df, by = "zip_code") |>
  nrow()

knitr::kable(head(zips_missing_zori, 10))
```

The final dataset contains 17516 observations with 149 unique zip codes across 43 distinct neighborhoods. An additional 171 zip codes that are in the metadata are not in the Zillow rental data, which probably means those areas either don't have enough rental listings or weren't included in Zillow's data collection for this specific dataset.

```{r}
#Comparing rental prices
price_change <- 
  zillowdata_df |>
  filter(date %in% c("2020-01-31", "2021-01-31")) |>
  group_by(zip_code, neighborhood, county) |>
  reframe(
    jan2020_price = rent_price[date == "2020-01-31"],
    jan2021_price = rent_price[date == "2021-01-31"],
    .groups = "drop"
  ) |>
  mutate(price_difference = jan2021_price - jan2020_price) |>
  filter(!is.na(price_difference)) |>

  arrange(price_difference) |>
  slice(1:10) |>
  select(-.groups) |>
  rename(borough = county)

knitr::kable(head(price_change, 10))
```
The neighborhoods with the biggest price change are mostly in the lower Manhattan area and are considered pretty expensive today. This can be a reflection of an outflux of residents during covid and a return by 2025.


